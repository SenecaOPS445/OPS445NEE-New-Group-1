#!/usr/bin/env python3
"""
Enhanced Backup Script with Time Tracking
"""

import shutil
import os
import argparse
from datetime import datetime
import time
import json

def valid_path(path):
    """Validate path exists with time logging"""
    check_time = datetime.now().isoformat()
    if os.path.exists(path):
        return True
    print(f"[{check_time}] Error: Path not found - {path}")
    return False

def backup_info(path):
    """Display backup stats with timestamp"""
    start_time = time.time()
    if not valid_path(path):
        return

    size = os.popen(f'du -sh "{path}"').read().strip()
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    print(f"\nBackup Analysis [{timestamp}]")
    print(f"Path: {path}")
    print(f"Size: {size}")
    print(f"Items: {sum(len(files) for _, _, files in os.walk(path)) if os.path.isdir(path) else 1}")
    print(f"Analysis duration: {time.time() - start_time:.2f}s")

def create_backup(source_path, backup_path):
    """Create timestamped backup with metadata"""
    if not valid_path(source_path):
        return False

    start_time = time.time()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_name = f"{os.path.basename(source_path)}_{timestamp}"
    full_backup_path = os.path.join(backup_path, backup_name)

    try:
        # Perform backup
        if os.path.isdir(source_path):
            shutil.copytree(source_path, full_backup_path)
            operation = "directory_copy"
        elif os.path.isfile(source_path):
            shutil.copy2(source_path, full_backup_path)
            operation = "file_copy"
        else:
            print(f"[{datetime.now().isoformat()}] Error: Invalid path type - {source_path}")
            return False

        # Create metadata
        metadata = {
            "backup_time": datetime.now().isoformat(),
            "source": source_path,
            "destination": full_backup_path,
            "operation": operation,
            "size_bytes": os.path.getsize(full_backup_path) if os.path.isfile(full_backup_path)
                          else sum(os.path.getsize(os.path.join(dirpath, filename)) 
                          for dirpath, _, filenames in os.walk(full_backup_path) 
                          for filename in filenames),
            "duration_sec": time.time() - start_time,
            "host": os.uname().nodename
        }

        with open(f"{full_backup_path}.meta", "w") as meta_file:
            json.dump(metadata, meta_file, indent=2)

        print(f"\nBackup completed at {metadata['backup_time']}")
        print(f"Source: {source_path}")
        print(f"Destination: {full_backup_path}")
        print(f"Size: {metadata['size_bytes']} bytes")
        print(f"Duration: {metadata['duration_sec']:.2f} seconds")
        return True

    except Exception as e:
        error_time = datetime.now().isoformat()
        print(f"[{error_time}] Backup failed: {str(e)}")
        return False

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Backup tool with time tracking")
    parser.add_argument("source", help="Path to source file/directory")
    parser.add_argument("destination", help="Backup destination directory")
    parser.add_argument("--info", action="store_true", help="Show backup info only")

    args = parser.parse_args()

    if args.info:
        backup_info(args.source)
    else:
        create_backup(args.source, args.destination)